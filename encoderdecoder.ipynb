{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONDowZauclWg2q+PexDjT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshantac/Random-projects/blob/master/encoderdecoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LsSj_KVboud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "797ce0bc-e0dc-4297-ab68-f2bec1814eae"
      },
      "source": [
        "!wget -q https://github.com/EVA4-RS-Group/Phase2/releases/download/S6/data.zip\n",
        "!unzip data.zip\n",
        "!rm -rf data.zip\n",
        "!mkdir models\n",
        "!mkdir samples"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/test/\n",
            "   creating: data/test/data_test/\n",
            "  inflating: data/test/data_test/desktop.ini  \n",
            "  inflating: data/test/data_test/img_002.jpg  \n",
            "  inflating: data/test/data_test/img_005.jpg  \n",
            "  inflating: data/test/data_test/img_012.jpg  \n",
            "  inflating: data/test/data_test/img_015.jpg  \n",
            "  inflating: data/test/data_test/img_022.jpg  \n",
            "  inflating: data/test/data_test/img_025.jpg  \n",
            "  inflating: data/test/data_test/img_032.jpg  \n",
            "  inflating: data/test/data_test/img_035.jpg  \n",
            "  inflating: data/test/data_test/img_042.jpg  \n",
            "  inflating: data/test/data_test/img_045.jpg  \n",
            "  inflating: data/test/data_test/img_052.jpg  \n",
            "  inflating: data/test/data_test/img_055.jpg  \n",
            "  inflating: data/test/data_test/img_062.jpg  \n",
            "  inflating: data/test/data_test/img_065.jpg  \n",
            "  inflating: data/test/data_test/img_072.jpg  \n",
            "  inflating: data/test/data_test/img_075.jpg  \n",
            "  inflating: data/test/data_test/img_082.jpg  \n",
            "  inflating: data/test/data_test/img_085.jpg  \n",
            "  inflating: data/test/data_test/img_092.jpg  \n",
            "  inflating: data/test/data_test/img_095.jpg  \n",
            "  inflating: data/test/data_test/img_102.jpg  \n",
            "  inflating: data/test/data_test/img_105.jpg  \n",
            "  inflating: data/test/data_test/img_112.jpg  \n",
            "  inflating: data/test/data_test/img_115.jpg  \n",
            "  inflating: data/test/data_test/img_122.jpg  \n",
            "  inflating: data/test/data_test/img_125.jpg  \n",
            "  inflating: data/test/data_test/img_132.jpg  \n",
            "  inflating: data/test/data_test/img_135.jpg  \n",
            "  inflating: data/test/data_test/img_142.jpg  \n",
            "  inflating: data/test/data_test/img_145.jpg  \n",
            "  inflating: data/test/data_test/img_152.jpg  \n",
            "  inflating: data/test/data_test/img_155.jpg  \n",
            "  inflating: data/test/data_test/img_162.jpg  \n",
            "  inflating: data/test/data_test/img_165.jpg  \n",
            "  inflating: data/test/data_test/img_172.jpg  \n",
            "  inflating: data/test/data_test/img_175.jpg  \n",
            "  inflating: data/test/data_test/img_182.jpg  \n",
            "  inflating: data/test/data_test/img_185.jpg  \n",
            "  inflating: data/test/data_test/img_192.jpg  \n",
            "  inflating: data/test/data_test/img_195.jpg  \n",
            "  inflating: data/test/data_test/img_202.jpg  \n",
            "  inflating: data/test/data_test/img_205.jpg  \n",
            "  inflating: data/test/data_test/img_212.jpg  \n",
            "  inflating: data/test/data_test/img_215.jpg  \n",
            "  inflating: data/test/data_test/img_222.jpg  \n",
            "  inflating: data/test/data_test/img_225.jpg  \n",
            "  inflating: data/test/data_test/img_232.jpg  \n",
            "  inflating: data/test/data_test/img_235.jpg  \n",
            "  inflating: data/test/data_test/img_242.jpg  \n",
            "  inflating: data/test/data_test/img_245.jpg  \n",
            "  inflating: data/test/data_test/img_252.jpg  \n",
            "  inflating: data/test/data_test/img_255.jpg  \n",
            "  inflating: data/test/data_test/img_262.jpg  \n",
            "  inflating: data/test/data_test/img_265.jpg  \n",
            "  inflating: data/test/data_test/img_272.jpg  \n",
            "  inflating: data/test/data_test/img_275.jpg  \n",
            "  inflating: data/test/data_test/img_282.jpg  \n",
            "  inflating: data/test/data_test/img_285.jpg  \n",
            "  inflating: data/test/data_test/img_292.jpg  \n",
            "  inflating: data/test/data_test/img_295.jpg  \n",
            "  inflating: data/test/data_test/img_302.jpg  \n",
            "  inflating: data/test/data_test/img_305.jpg  \n",
            "  inflating: data/test/data_test/img_312.jpg  \n",
            "  inflating: data/test/data_test/img_315.jpg  \n",
            "  inflating: data/test/data_test/img_322.jpg  \n",
            "  inflating: data/test/data_test/img_325.jpg  \n",
            "  inflating: data/test/data_test/img_332.jpg  \n",
            "  inflating: data/test/data_test/img_335.jpg  \n",
            "  inflating: data/test/data_test/img_342.jpg  \n",
            "  inflating: data/test/data_test/img_345.jpg  \n",
            "  inflating: data/test/data_test/img_352.jpg  \n",
            "  inflating: data/test/data_test/img_355.jpg  \n",
            "  inflating: data/test/data_test/img_362.jpg  \n",
            "  inflating: data/test/data_test/img_365.jpg  \n",
            "  inflating: data/test/data_test/img_372.jpg  \n",
            "  inflating: data/test/data_test/img_375.jpg  \n",
            "  inflating: data/test/data_test/img_382.jpg  \n",
            "  inflating: data/test/data_test/img_385.jpg  \n",
            "  inflating: data/test/data_test/img_392.jpg  \n",
            "  inflating: data/test/data_test/img_395.jpg  \n",
            "  inflating: data/test/data_test/img_402.jpg  \n",
            "  inflating: data/test/data_test/img_405.jpg  \n",
            "  inflating: data/test/data_test/img_412.jpg  \n",
            "  inflating: data/test/data_test/img_415.jpg  \n",
            "  inflating: data/test/data_test/img_422.jpg  \n",
            "  inflating: data/test/data_test/img_425.jpg  \n",
            "  inflating: data/test/data_test/img_432.jpg  \n",
            "  inflating: data/test/data_test/img_435.jpg  \n",
            "  inflating: data/test/data_test/img_442.jpg  \n",
            "  inflating: data/test/data_test/img_445.jpg  \n",
            "  inflating: data/test/data_test/img_452.jpg  \n",
            "  inflating: data/test/data_test/img_455.jpg  \n",
            "  inflating: data/test/data_test/img_462.jpg  \n",
            "  inflating: data/test/data_test/img_465.jpg  \n",
            "  inflating: data/test/data_test/img_472.jpg  \n",
            "  inflating: data/test/data_test/img_475.jpg  \n",
            "  inflating: data/test/data_test/img_482.jpg  \n",
            "  inflating: data/test/data_test/img_485.jpg  \n",
            "  inflating: data/test/data_test/img_492.jpg  \n",
            "  inflating: data/test/data_test/img_495.jpg  \n",
            "  inflating: data/test/data_test/img_502.jpg  \n",
            "  inflating: data/test/data_test/img_505.jpg  \n",
            "  inflating: data/test/desktop.ini   \n",
            "   creating: data/train/\n",
            "   creating: data/train/data_train/\n",
            "  inflating: data/train/data_train/img_000.jpg  \n",
            "  inflating: data/train/data_train/img_001.jpg  \n",
            "  inflating: data/train/data_train/img_003.jpg  \n",
            "  inflating: data/train/data_train/img_004.jpg  \n",
            "  inflating: data/train/data_train/img_006.jpg  \n",
            "  inflating: data/train/data_train/img_007.jpg  \n",
            "  inflating: data/train/data_train/img_008.jpg  \n",
            "  inflating: data/train/data_train/img_009.jpg  \n",
            "  inflating: data/train/data_train/img_010.jpg  \n",
            "  inflating: data/train/data_train/img_011.jpg  \n",
            "  inflating: data/train/data_train/img_013.jpg  \n",
            "  inflating: data/train/data_train/img_014.jpg  \n",
            "  inflating: data/train/data_train/img_016.jpg  \n",
            "  inflating: data/train/data_train/img_017.jpg  \n",
            "  inflating: data/train/data_train/img_018.jpg  \n",
            "  inflating: data/train/data_train/img_019.jpg  \n",
            "  inflating: data/train/data_train/img_020.jpg  \n",
            "  inflating: data/train/data_train/img_021.jpg  \n",
            "  inflating: data/train/data_train/img_023.jpg  \n",
            "  inflating: data/train/data_train/img_024.jpg  \n",
            "  inflating: data/train/data_train/img_026.jpg  \n",
            "  inflating: data/train/data_train/img_027.jpg  \n",
            "  inflating: data/train/data_train/img_028.jpg  \n",
            "  inflating: data/train/data_train/img_029.jpg  \n",
            "  inflating: data/train/data_train/img_030.jpg  \n",
            "  inflating: data/train/data_train/img_031.jpg  \n",
            "  inflating: data/train/data_train/img_033.jpg  \n",
            "  inflating: data/train/data_train/img_034.jpg  \n",
            "  inflating: data/train/data_train/img_036.jpg  \n",
            "  inflating: data/train/data_train/img_037.jpg  \n",
            "  inflating: data/train/data_train/img_038.jpg  \n",
            "  inflating: data/train/data_train/img_039.jpg  \n",
            "  inflating: data/train/data_train/img_040.jpg  \n",
            "  inflating: data/train/data_train/img_041.jpg  \n",
            "  inflating: data/train/data_train/img_043.jpg  \n",
            "  inflating: data/train/data_train/img_044.jpg  \n",
            "  inflating: data/train/data_train/img_046.jpg  \n",
            "  inflating: data/train/data_train/img_047.jpg  \n",
            "  inflating: data/train/data_train/img_048.jpg  \n",
            "  inflating: data/train/data_train/img_049.jpg  \n",
            "  inflating: data/train/data_train/img_050.jpg  \n",
            "  inflating: data/train/data_train/img_051.jpg  \n",
            "  inflating: data/train/data_train/img_053.jpg  \n",
            "  inflating: data/train/data_train/img_054.jpg  \n",
            "  inflating: data/train/data_train/img_056.jpg  \n",
            "  inflating: data/train/data_train/img_057.jpg  \n",
            "  inflating: data/train/data_train/img_058.jpg  \n",
            "  inflating: data/train/data_train/img_059.jpg  \n",
            "  inflating: data/train/data_train/img_060.jpg  \n",
            "  inflating: data/train/data_train/img_061.jpg  \n",
            "  inflating: data/train/data_train/img_063.jpg  \n",
            "  inflating: data/train/data_train/img_064.jpg  \n",
            "  inflating: data/train/data_train/img_066.jpg  \n",
            "  inflating: data/train/data_train/img_067.jpg  \n",
            "  inflating: data/train/data_train/img_068.jpg  \n",
            "  inflating: data/train/data_train/img_069.jpg  \n",
            "  inflating: data/train/data_train/img_070.jpg  \n",
            "  inflating: data/train/data_train/img_071.jpg  \n",
            "  inflating: data/train/data_train/img_073.jpg  \n",
            "  inflating: data/train/data_train/img_074.jpg  \n",
            "  inflating: data/train/data_train/img_076.jpg  \n",
            "  inflating: data/train/data_train/img_077.jpg  \n",
            "  inflating: data/train/data_train/img_078.jpg  \n",
            "  inflating: data/train/data_train/img_079.jpg  \n",
            "  inflating: data/train/data_train/img_080.jpg  \n",
            "  inflating: data/train/data_train/img_081.jpg  \n",
            "  inflating: data/train/data_train/img_083.jpg  \n",
            "  inflating: data/train/data_train/img_084.jpg  \n",
            "  inflating: data/train/data_train/img_086.jpg  \n",
            "  inflating: data/train/data_train/img_087.jpg  \n",
            "  inflating: data/train/data_train/img_088.jpg  \n",
            "  inflating: data/train/data_train/img_089.jpg  \n",
            "  inflating: data/train/data_train/img_090.jpg  \n",
            "  inflating: data/train/data_train/img_091.jpg  \n",
            "  inflating: data/train/data_train/img_093.jpg  \n",
            "  inflating: data/train/data_train/img_094.jpg  \n",
            "  inflating: data/train/data_train/img_096.jpg  \n",
            "  inflating: data/train/data_train/img_097.jpg  \n",
            "  inflating: data/train/data_train/img_098.jpg  \n",
            "  inflating: data/train/data_train/img_099.jpg  \n",
            "  inflating: data/train/data_train/img_100.jpg  \n",
            "  inflating: data/train/data_train/img_101.jpg  \n",
            "  inflating: data/train/data_train/img_103.jpg  \n",
            "  inflating: data/train/data_train/img_104.jpg  \n",
            "  inflating: data/train/data_train/img_106.jpg  \n",
            "  inflating: data/train/data_train/img_107.jpg  \n",
            "  inflating: data/train/data_train/img_108.jpg  \n",
            "  inflating: data/train/data_train/img_109.jpg  \n",
            "  inflating: data/train/data_train/img_110.jpg  \n",
            "  inflating: data/train/data_train/img_111.jpg  \n",
            "  inflating: data/train/data_train/img_113.jpg  \n",
            "  inflating: data/train/data_train/img_114.jpg  \n",
            "  inflating: data/train/data_train/img_116.jpg  \n",
            "  inflating: data/train/data_train/img_117.jpg  \n",
            "  inflating: data/train/data_train/img_118.jpg  \n",
            "  inflating: data/train/data_train/img_119.jpg  \n",
            "  inflating: data/train/data_train/img_120.jpg  \n",
            "  inflating: data/train/data_train/img_121.jpg  \n",
            "  inflating: data/train/data_train/img_123.jpg  \n",
            "  inflating: data/train/data_train/img_124.jpg  \n",
            "  inflating: data/train/data_train/img_126.jpg  \n",
            "  inflating: data/train/data_train/img_127.jpg  \n",
            "  inflating: data/train/data_train/img_128.jpg  \n",
            "  inflating: data/train/data_train/img_129.jpg  \n",
            "  inflating: data/train/data_train/img_130.jpg  \n",
            "  inflating: data/train/data_train/img_131.jpg  \n",
            "  inflating: data/train/data_train/img_133.jpg  \n",
            "  inflating: data/train/data_train/img_134.jpg  \n",
            "  inflating: data/train/data_train/img_136.jpg  \n",
            "  inflating: data/train/data_train/img_137.jpg  \n",
            "  inflating: data/train/data_train/img_138.jpg  \n",
            "  inflating: data/train/data_train/img_139.jpg  \n",
            "  inflating: data/train/data_train/img_140.jpg  \n",
            "  inflating: data/train/data_train/img_141.jpg  \n",
            "  inflating: data/train/data_train/img_143.jpg  \n",
            "  inflating: data/train/data_train/img_144.jpg  \n",
            "  inflating: data/train/data_train/img_146.jpg  \n",
            "  inflating: data/train/data_train/img_147.jpg  \n",
            "  inflating: data/train/data_train/img_148.jpg  \n",
            "  inflating: data/train/data_train/img_149.jpg  \n",
            "  inflating: data/train/data_train/img_150.jpg  \n",
            "  inflating: data/train/data_train/img_151.jpg  \n",
            "  inflating: data/train/data_train/img_153.jpg  \n",
            "  inflating: data/train/data_train/img_154.jpg  \n",
            "  inflating: data/train/data_train/img_156.jpg  \n",
            "  inflating: data/train/data_train/img_157.jpg  \n",
            "  inflating: data/train/data_train/img_158.jpg  \n",
            "  inflating: data/train/data_train/img_159.jpg  \n",
            "  inflating: data/train/data_train/img_160.jpg  \n",
            "  inflating: data/train/data_train/img_161.jpg  \n",
            "  inflating: data/train/data_train/img_163.jpg  \n",
            "  inflating: data/train/data_train/img_164.jpg  \n",
            "  inflating: data/train/data_train/img_166.jpg  \n",
            "  inflating: data/train/data_train/img_167.jpg  \n",
            "  inflating: data/train/data_train/img_168.jpg  \n",
            "  inflating: data/train/data_train/img_169.jpg  \n",
            "  inflating: data/train/data_train/img_170.jpg  \n",
            "  inflating: data/train/data_train/img_171.jpg  \n",
            "  inflating: data/train/data_train/img_173.jpg  \n",
            "  inflating: data/train/data_train/img_174.jpg  \n",
            "  inflating: data/train/data_train/img_176.jpg  \n",
            "  inflating: data/train/data_train/img_177.jpg  \n",
            "  inflating: data/train/data_train/img_178.jpg  \n",
            "  inflating: data/train/data_train/img_179.jpg  \n",
            "  inflating: data/train/data_train/img_180.jpg  \n",
            "  inflating: data/train/data_train/img_181.jpg  \n",
            "  inflating: data/train/data_train/img_183.jpg  \n",
            "  inflating: data/train/data_train/img_184.jpg  \n",
            "  inflating: data/train/data_train/img_186.jpg  \n",
            "  inflating: data/train/data_train/img_187.jpg  \n",
            "  inflating: data/train/data_train/img_188.jpg  \n",
            "  inflating: data/train/data_train/img_189.jpg  \n",
            "  inflating: data/train/data_train/img_190.jpg  \n",
            "  inflating: data/train/data_train/img_191.jpg  \n",
            "  inflating: data/train/data_train/img_193.jpg  \n",
            "  inflating: data/train/data_train/img_194.jpg  \n",
            "  inflating: data/train/data_train/img_196.jpg  \n",
            "  inflating: data/train/data_train/img_197.jpg  \n",
            "  inflating: data/train/data_train/img_198.jpg  \n",
            "  inflating: data/train/data_train/img_199.jpg  \n",
            "  inflating: data/train/data_train/img_200.jpg  \n",
            "  inflating: data/train/data_train/img_201.jpg  \n",
            "  inflating: data/train/data_train/img_203.jpg  \n",
            "  inflating: data/train/data_train/img_204.jpg  \n",
            "  inflating: data/train/data_train/img_206.jpg  \n",
            "  inflating: data/train/data_train/img_207.jpg  \n",
            "  inflating: data/train/data_train/img_208.jpg  \n",
            "  inflating: data/train/data_train/img_209.jpg  \n",
            "  inflating: data/train/data_train/img_210.jpg  \n",
            "  inflating: data/train/data_train/img_211.jpg  \n",
            "  inflating: data/train/data_train/img_213.jpg  \n",
            "  inflating: data/train/data_train/img_214.jpg  \n",
            "  inflating: data/train/data_train/img_216.jpg  \n",
            "  inflating: data/train/data_train/img_217.jpg  \n",
            "  inflating: data/train/data_train/img_218.jpg  \n",
            "  inflating: data/train/data_train/img_219.jpg  \n",
            "  inflating: data/train/data_train/img_220.jpg  \n",
            "  inflating: data/train/data_train/img_221.jpg  \n",
            "  inflating: data/train/data_train/img_223.jpg  \n",
            "  inflating: data/train/data_train/img_224.jpg  \n",
            "  inflating: data/train/data_train/img_226.jpg  \n",
            "  inflating: data/train/data_train/img_227.jpg  \n",
            "  inflating: data/train/data_train/img_228.jpg  \n",
            "  inflating: data/train/data_train/img_229.jpg  \n",
            "  inflating: data/train/data_train/img_230.jpg  \n",
            "  inflating: data/train/data_train/img_231.jpg  \n",
            "  inflating: data/train/data_train/img_233.jpg  \n",
            "  inflating: data/train/data_train/img_234.jpg  \n",
            "  inflating: data/train/data_train/img_236.jpg  \n",
            "  inflating: data/train/data_train/img_237.jpg  \n",
            "  inflating: data/train/data_train/img_238.jpg  \n",
            "  inflating: data/train/data_train/img_239.jpg  \n",
            "  inflating: data/train/data_train/img_240.jpg  \n",
            "  inflating: data/train/data_train/img_241.jpg  \n",
            "  inflating: data/train/data_train/img_243.jpg  \n",
            "  inflating: data/train/data_train/img_244.jpg  \n",
            "  inflating: data/train/data_train/img_246.jpg  \n",
            "  inflating: data/train/data_train/img_247.jpg  \n",
            "  inflating: data/train/data_train/img_248.jpg  \n",
            "  inflating: data/train/data_train/img_249.jpg  \n",
            "  inflating: data/train/data_train/img_250.jpg  \n",
            "  inflating: data/train/data_train/img_251.jpg  \n",
            "  inflating: data/train/data_train/img_253.jpg  \n",
            "  inflating: data/train/data_train/img_254.jpg  \n",
            "  inflating: data/train/data_train/img_256.jpg  \n",
            "  inflating: data/train/data_train/img_257.jpg  \n",
            "  inflating: data/train/data_train/img_258.jpg  \n",
            "  inflating: data/train/data_train/img_259.jpg  \n",
            "  inflating: data/train/data_train/img_260.jpg  \n",
            "  inflating: data/train/data_train/img_261.jpg  \n",
            "  inflating: data/train/data_train/img_263.jpg  \n",
            "  inflating: data/train/data_train/img_264.jpg  \n",
            "  inflating: data/train/data_train/img_266.jpg  \n",
            "  inflating: data/train/data_train/img_267.jpg  \n",
            "  inflating: data/train/data_train/img_268.jpg  \n",
            "  inflating: data/train/data_train/img_269.jpg  \n",
            "  inflating: data/train/data_train/img_270.jpg  \n",
            "  inflating: data/train/data_train/img_271.jpg  \n",
            "  inflating: data/train/data_train/img_273.jpg  \n",
            "  inflating: data/train/data_train/img_274.jpg  \n",
            "  inflating: data/train/data_train/img_276.jpg  \n",
            "  inflating: data/train/data_train/img_277.jpg  \n",
            "  inflating: data/train/data_train/img_278.jpg  \n",
            "  inflating: data/train/data_train/img_279.jpg  \n",
            "  inflating: data/train/data_train/img_280.jpg  \n",
            "  inflating: data/train/data_train/img_281.jpg  \n",
            "  inflating: data/train/data_train/img_283.jpg  \n",
            "  inflating: data/train/data_train/img_284.jpg  \n",
            "  inflating: data/train/data_train/img_286.jpg  \n",
            "  inflating: data/train/data_train/img_287.jpg  \n",
            "  inflating: data/train/data_train/img_288.jpg  \n",
            "  inflating: data/train/data_train/img_289.jpg  \n",
            "  inflating: data/train/data_train/img_290.jpg  \n",
            "  inflating: data/train/data_train/img_291.jpg  \n",
            "  inflating: data/train/data_train/img_293.jpg  \n",
            "  inflating: data/train/data_train/img_294.jpg  \n",
            "  inflating: data/train/data_train/img_296.jpg  \n",
            "  inflating: data/train/data_train/img_297.jpg  \n",
            "  inflating: data/train/data_train/img_298.jpg  \n",
            "  inflating: data/train/data_train/img_299.jpg  \n",
            "  inflating: data/train/data_train/img_300.jpg  \n",
            "  inflating: data/train/data_train/img_301.jpg  \n",
            "  inflating: data/train/data_train/img_303.jpg  \n",
            "  inflating: data/train/data_train/img_304.jpg  \n",
            "  inflating: data/train/data_train/img_306.jpg  \n",
            "  inflating: data/train/data_train/img_307.jpg  \n",
            "  inflating: data/train/data_train/img_308.jpg  \n",
            "  inflating: data/train/data_train/img_309.jpg  \n",
            "  inflating: data/train/data_train/img_310.jpg  \n",
            "  inflating: data/train/data_train/img_311.jpg  \n",
            "  inflating: data/train/data_train/img_313.jpg  \n",
            "  inflating: data/train/data_train/img_314.jpg  \n",
            "  inflating: data/train/data_train/img_316.jpg  \n",
            "  inflating: data/train/data_train/img_317.jpg  \n",
            "  inflating: data/train/data_train/img_318.jpg  \n",
            "  inflating: data/train/data_train/img_319.jpg  \n",
            "  inflating: data/train/data_train/img_320.jpg  \n",
            "  inflating: data/train/data_train/img_321.jpg  \n",
            "  inflating: data/train/data_train/img_323.jpg  \n",
            "  inflating: data/train/data_train/img_324.jpg  \n",
            "  inflating: data/train/data_train/img_326.jpg  \n",
            "  inflating: data/train/data_train/img_327.jpg  \n",
            "  inflating: data/train/data_train/img_328.jpg  \n",
            "  inflating: data/train/data_train/img_329.jpg  \n",
            "  inflating: data/train/data_train/img_330.jpg  \n",
            "  inflating: data/train/data_train/img_331.jpg  \n",
            "  inflating: data/train/data_train/img_333.jpg  \n",
            "  inflating: data/train/data_train/img_334.jpg  \n",
            "  inflating: data/train/data_train/img_336.jpg  \n",
            "  inflating: data/train/data_train/img_337.jpg  \n",
            "  inflating: data/train/data_train/img_338.jpg  \n",
            "  inflating: data/train/data_train/img_339.jpg  \n",
            "  inflating: data/train/data_train/img_340.jpg  \n",
            "  inflating: data/train/data_train/img_341.jpg  \n",
            "  inflating: data/train/data_train/img_343.jpg  \n",
            "  inflating: data/train/data_train/img_344.jpg  \n",
            "  inflating: data/train/data_train/img_346.jpg  \n",
            "  inflating: data/train/data_train/img_347.jpg  \n",
            "  inflating: data/train/data_train/img_348.jpg  \n",
            "  inflating: data/train/data_train/img_349.jpg  \n",
            "  inflating: data/train/data_train/img_350.jpg  \n",
            "  inflating: data/train/data_train/img_351.jpg  \n",
            "  inflating: data/train/data_train/img_353.jpg  \n",
            "  inflating: data/train/data_train/img_354.jpg  \n",
            "  inflating: data/train/data_train/img_356.jpg  \n",
            "  inflating: data/train/data_train/img_357.jpg  \n",
            "  inflating: data/train/data_train/img_358.jpg  \n",
            "  inflating: data/train/data_train/img_359.jpg  \n",
            "  inflating: data/train/data_train/img_360.jpg  \n",
            "  inflating: data/train/data_train/img_361.jpg  \n",
            "  inflating: data/train/data_train/img_363.jpg  \n",
            "  inflating: data/train/data_train/img_364.jpg  \n",
            "  inflating: data/train/data_train/img_366.jpg  \n",
            "  inflating: data/train/data_train/img_367.jpg  \n",
            "  inflating: data/train/data_train/img_368.jpg  \n",
            "  inflating: data/train/data_train/img_369.jpg  \n",
            "  inflating: data/train/data_train/img_370.jpg  \n",
            "  inflating: data/train/data_train/img_371.jpg  \n",
            "  inflating: data/train/data_train/img_373.jpg  \n",
            "  inflating: data/train/data_train/img_374.jpg  \n",
            "  inflating: data/train/data_train/img_376.jpg  \n",
            "  inflating: data/train/data_train/img_377.jpg  \n",
            "  inflating: data/train/data_train/img_378.jpg  \n",
            "  inflating: data/train/data_train/img_379.jpg  \n",
            "  inflating: data/train/data_train/img_380.jpg  \n",
            "  inflating: data/train/data_train/img_381.jpg  \n",
            "  inflating: data/train/data_train/img_383.jpg  \n",
            "  inflating: data/train/data_train/img_384.jpg  \n",
            "  inflating: data/train/data_train/img_386.jpg  \n",
            "  inflating: data/train/data_train/img_387.jpg  \n",
            "  inflating: data/train/data_train/img_388.jpg  \n",
            "  inflating: data/train/data_train/img_389.jpg  \n",
            "  inflating: data/train/data_train/img_390.jpg  \n",
            "  inflating: data/train/data_train/img_391.jpg  \n",
            "  inflating: data/train/data_train/img_393.jpg  \n",
            "  inflating: data/train/data_train/img_394.jpg  \n",
            "  inflating: data/train/data_train/img_396.jpg  \n",
            "  inflating: data/train/data_train/img_397.jpg  \n",
            "  inflating: data/train/data_train/img_398.jpg  \n",
            "  inflating: data/train/data_train/img_399.jpg  \n",
            "  inflating: data/train/data_train/img_400.jpg  \n",
            "  inflating: data/train/data_train/img_401.jpg  \n",
            "  inflating: data/train/data_train/img_403.jpg  \n",
            "  inflating: data/train/data_train/img_404.jpg  \n",
            "  inflating: data/train/data_train/img_406.jpg  \n",
            "  inflating: data/train/data_train/img_407.jpg  \n",
            "  inflating: data/train/data_train/img_408.jpg  \n",
            "  inflating: data/train/data_train/img_409.jpg  \n",
            "  inflating: data/train/data_train/img_410.jpg  \n",
            "  inflating: data/train/data_train/img_411.jpg  \n",
            "  inflating: data/train/data_train/img_413.jpg  \n",
            "  inflating: data/train/data_train/img_414.jpg  \n",
            "  inflating: data/train/data_train/img_416.jpg  \n",
            "  inflating: data/train/data_train/img_417.jpg  \n",
            "  inflating: data/train/data_train/img_418.jpg  \n",
            "  inflating: data/train/data_train/img_419.jpg  \n",
            "  inflating: data/train/data_train/img_420.jpg  \n",
            "  inflating: data/train/data_train/img_421.jpg  \n",
            "  inflating: data/train/data_train/img_423.jpg  \n",
            "  inflating: data/train/data_train/img_424.jpg  \n",
            "  inflating: data/train/data_train/img_426.jpg  \n",
            "  inflating: data/train/data_train/img_427.jpg  \n",
            "  inflating: data/train/data_train/img_428.jpg  \n",
            "  inflating: data/train/data_train/img_429.jpg  \n",
            "  inflating: data/train/data_train/img_430.jpg  \n",
            "  inflating: data/train/data_train/img_431.jpg  \n",
            "  inflating: data/train/data_train/img_433.jpg  \n",
            "  inflating: data/train/data_train/img_434.jpg  \n",
            "  inflating: data/train/data_train/img_436.jpg  \n",
            "  inflating: data/train/data_train/img_437.jpg  \n",
            "  inflating: data/train/data_train/img_438.jpg  \n",
            "  inflating: data/train/data_train/img_439.jpg  \n",
            "  inflating: data/train/data_train/img_440.jpg  \n",
            "  inflating: data/train/data_train/img_441.jpg  \n",
            "  inflating: data/train/data_train/img_443.jpg  \n",
            "  inflating: data/train/data_train/img_444.jpg  \n",
            "  inflating: data/train/data_train/img_446.jpg  \n",
            "  inflating: data/train/data_train/img_447.jpg  \n",
            "  inflating: data/train/data_train/img_448.jpg  \n",
            "  inflating: data/train/data_train/img_449.jpg  \n",
            "  inflating: data/train/data_train/img_450.jpg  \n",
            "  inflating: data/train/data_train/img_451.jpg  \n",
            "  inflating: data/train/data_train/img_453.jpg  \n",
            "  inflating: data/train/data_train/img_454.jpg  \n",
            "  inflating: data/train/data_train/img_456.jpg  \n",
            "  inflating: data/train/data_train/img_457.jpg  \n",
            "  inflating: data/train/data_train/img_458.jpg  \n",
            "  inflating: data/train/data_train/img_459.jpg  \n",
            "  inflating: data/train/data_train/img_460.jpg  \n",
            "  inflating: data/train/data_train/img_461.jpg  \n",
            "  inflating: data/train/data_train/img_463.jpg  \n",
            "  inflating: data/train/data_train/img_464.jpg  \n",
            "  inflating: data/train/data_train/img_466.jpg  \n",
            "  inflating: data/train/data_train/img_467.jpg  \n",
            "  inflating: data/train/data_train/img_468.jpg  \n",
            "  inflating: data/train/data_train/img_469.jpg  \n",
            "  inflating: data/train/data_train/img_470.jpg  \n",
            "  inflating: data/train/data_train/img_471.jpg  \n",
            "  inflating: data/train/data_train/img_473.jpg  \n",
            "  inflating: data/train/data_train/img_474.jpg  \n",
            "  inflating: data/train/data_train/img_476.jpg  \n",
            "  inflating: data/train/data_train/img_477.jpg  \n",
            "  inflating: data/train/data_train/img_478.jpg  \n",
            "  inflating: data/train/data_train/img_479.jpg  \n",
            "  inflating: data/train/data_train/img_480.jpg  \n",
            "  inflating: data/train/data_train/img_481.jpg  \n",
            "  inflating: data/train/data_train/img_483.jpg  \n",
            "  inflating: data/train/data_train/img_484.jpg  \n",
            "  inflating: data/train/data_train/img_486.jpg  \n",
            "  inflating: data/train/data_train/img_487.jpg  \n",
            "  inflating: data/train/data_train/img_488.jpg  \n",
            "  inflating: data/train/data_train/img_489.jpg  \n",
            "  inflating: data/train/data_train/img_490.jpg  \n",
            "  inflating: data/train/data_train/img_491.jpg  \n",
            "  inflating: data/train/data_train/img_493.jpg  \n",
            "  inflating: data/train/data_train/img_494.jpg  \n",
            "  inflating: data/train/data_train/img_496.jpg  \n",
            "  inflating: data/train/data_train/img_497.jpg  \n",
            "  inflating: data/train/data_train/img_498.jpg  \n",
            "  inflating: data/train/data_train/img_499.jpg  \n",
            "  inflating: data/train/data_train/img_500.jpg  \n",
            "  inflating: data/train/data_train/img_501.jpg  \n",
            "  inflating: data/train/data_train/img_503.jpg  \n",
            "  inflating: data/train/data_train/img_504.jpg  \n",
            "  inflating: data/train/data_train/img_506.jpg  \n",
            "  inflating: data/train/data_train/img_507.jpg  \n",
            "  inflating: data/train/data_train/img_508.jpg  \n",
            "  inflating: data/train/data_train/img_509.jpg  \n",
            "  inflating: data/train/data_train/img_510.jpg  \n",
            "  inflating: data/train/data_train/img_511.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIo9l2fJVyGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir models\n",
        "!mkdir samples"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifkYl0L3azDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ba25155-8dfe-4201-84c3-cd4d442bc414"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0Yg5mHuoWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions import kl_divergence\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g6LaCf4uwMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = True\n",
        "SEED = 2\n",
        "BATCH_SIZE = 128\n",
        "LOG_INTERVAL = 10\n",
        "EPOCHS = 10\n",
        "ZDIMS = 800 #36"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgaIL_ck-75V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(SEED)\n",
        "if CUDA:\n",
        "    torch.cuda.manual_seed(SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgA1Hr_ou0aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# # I do this so that the MNIST dataset is downloaded where I want it\n",
        "# #os.chdir(\"/home/cpbotha/Downloads/pytorch-vae\")\n",
        "\n",
        "\n",
        "\n",
        "# # DataLoader instances will load tensors directly into GPU memory\n",
        "# kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
        "\n",
        "# # Download or load downloaded MNIST dataset\n",
        "# # shuffle data at every epoch\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('data', train=True, download=True,\n",
        "#                    transform=transforms.ToTensor()),\n",
        "#     batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "\n",
        "# # Same for test data\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
        "#     batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JnUSXSEzXN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "                                std=(0.5, 0.5, 0.5))\n",
        "                               ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG9b_25UvJRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test = datasets.ImageFolder('data/test/', transform=transform)\n",
        "test_loader = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "dataset_train = datasets.ImageFolder('data/train/', transform=transform)\n",
        "train_loader = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKCCdP5XU3FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        try:\n",
        "            nn.init.xavier_uniform_(m.weight.data)\n",
        "            m.bias.data.fill_(0)\n",
        "        except AttributeError:\n",
        "            print(\"Skipping initialization of \", classname)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyuVbw12spcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, dim, z_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 5, 1, 0),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, z_dim * 2, 3, 1, 0),\n",
        "            nn.BatchNorm2d(z_dim * 2)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, dim, 3, 1, 0),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(dim, dim, 5, 1, 0),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(dim, dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(dim, input_dim, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.apply(weights_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x).chunk(2, dim=1)\n",
        "\n",
        "        q_z_x = Normal(mu, logvar.mul(.5).exp())\n",
        "        p_z = Normal(torch.zeros_like(mu), torch.ones_like(logvar))\n",
        "        kl_div = kl_divergence(q_z_x, p_z).sum(1).mean()\n",
        "\n",
        "        x_tilde = self.decoder(q_z_x.rsample())\n",
        "        return x_tilde, kl_div\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d8fJHfvvGWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not this \n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # ENCODER\n",
        "        # 28 x 28 pixels = 784 input pixels, 400 outputs\n",
        "        self.fc0 = nn.Conv2d(3,1,3,1,2)\n",
        "        self.fc1 = nn.Linear(16384, 8000)\n",
        "        # rectified linear unit layer from 400 to 400\n",
        "        # max(0, x)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc21 = nn.Linear(8000, ZDIMS)  # mu layer\n",
        "        self.fc22 = nn.Linear(8000, ZDIMS)  # logvariance layer\n",
        "        # this last layer bottlenecks through ZDIMS connections\n",
        "\n",
        "        # DECODER\n",
        "        # from bottleneck to hidden 400\n",
        "        self.fc3 = nn.Linear(ZDIMS, 8000)\n",
        "        # from hidden 400 to 784 outputs\n",
        "        self.fc4 = nn.Linear(8000, 16384)\n",
        "        self.fc5 = nn.Conv2d(1,3,3,1,2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def encode(self, x: Variable) -> (Variable, Variable):\n",
        "        \"\"\"Input vector x -> fully connected 1 -> ReLU -> (fully connected\n",
        "        21, fully connected 22)\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : [128, 784] matrix; 128 digits of 28x28 pixels each\n",
        "        Returns\n",
        "        -------\n",
        "        (mu, logvar) : ZDIMS mean units one for each latent dimension, ZDIMS\n",
        "            variance units one for each latent dimension\n",
        "        \"\"\"\n",
        "\n",
        "        # h1 is [128, 400]\n",
        "        h1 = self.relu(self.fc1(self.fc0(x)))  # type: Variable\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparameterize(self, mu: Variable, logvar: Variable) -> Variable:\n",
        "        \"\"\"THE REPARAMETERIZATION IDEA:\n",
        "\n",
        "        For each training sample (we get 128 batched at a time)\n",
        "\n",
        "        - take the current learned mu, stddev for each of the ZDIMS\n",
        "          dimensions and draw a random sample from that distribution\n",
        "        - the whole network is trained so that these randomly drawn\n",
        "          samples decode to output that looks like the input\n",
        "        - which will mean that the std, mu will be learned\n",
        "          *distributions* that correctly encode the inputs\n",
        "        - due to the additional KLD term (see loss_function() below)\n",
        "          the distribution will tend to unit Gaussians\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu : [128, ZDIMS] mean matrix\n",
        "        logvar : [128, ZDIMS] variance matrix\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        During training random sample from the learned ZDIMS-dimensional\n",
        "        normal distribution; during inference its mean.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.training:\n",
        "            # multiply log variance with 0.5, then in-place exponent\n",
        "            # yielding the standard deviation\n",
        "            std = logvar.mul(0.5).exp_()  # type: Variable\n",
        "            # - std.data is the [128,ZDIMS] tensor that is wrapped by std\n",
        "            # - so eps is [128,ZDIMS] with all elements drawn from a mean 0\n",
        "            #   and stddev 1 normal distribution that is 128 samples\n",
        "            #   of random ZDIMS-float vectors\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            # - sample from a normal distribution with standard\n",
        "            #   deviation = std and mean = mu by multiplying mean 0\n",
        "            #   stddev 1 sample with desired std and mu, see\n",
        "            #   https://stats.stackexchange.com/a/16338\n",
        "            # - so we have 128 sets (the batch) of random ZDIMS-float\n",
        "            #   vectors sampled from normal distribution with learned\n",
        "            #   std and mu for the current input\n",
        "            return eps.mul(std).add_(mu)\n",
        "\n",
        "        else:\n",
        "            # During inference, we simply spit out the mean of the\n",
        "            # learned distribution for the current input.  We could\n",
        "            # use a random sample from the distribution, but mu of\n",
        "            # course has the highest probability.\n",
        "            return mu\n",
        "\n",
        "    def decode(self, z: Variable) -> Variable:\n",
        "        h3 = self.relu(self.fc3(z))\n",
        "        return self.sigmoid(self.fc5(self.fc4(h3)))\n",
        "\n",
        "    def forward(self, x: Variable) -> (Variable, Variable, Variable):\n",
        "        mu, logvar = self.encode(x.view(-1, 16384))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1hWiitRshPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 3\n",
        "DIM = 256\n",
        "Z_DIM = 128"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eELWfsiEhj1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VAE()\n",
        "#model = VAE(INPUT_DIM, DIM, Z_DIM)\n",
        "if CUDA:\n",
        "    model.cuda()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXQAccQOJHvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "N_EPOCHS = 150\n",
        "PRINT_INTERVAL = 500\n",
        "DATASET = 'DATATSET' #'FashionMNIST'  # CIFAR10 | MNIST | FashionMNIST\n",
        "NUM_WORKERS = 4"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXJn7yx4pPbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3, amsgrad=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZScXfYr7pNLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# def train():\n",
        "#     train_loss = []\n",
        "#     model.train()\n",
        "#     for batch_idx, (x, _) in enumerate(train_loader):\n",
        "#         start_time = time.time()\n",
        "#         x = x.cuda()\n",
        "\n",
        "#         x_tilde, kl_d = model(x)\n",
        "#         loss_recons = F.mse_loss(x_tilde, x, size_average=False) / x.size(0)\n",
        "#         loss = loss_recons + kl_d\n",
        "\n",
        "#         nll = -Normal(x_tilde, torch.ones_like(x_tilde)).log_prob(x)\n",
        "#         log_px = nll.mean().item() - np.log(128) + kl_d.item()\n",
        "#         log_px /= np.log(2)\n",
        "\n",
        "#         opt.zero_grad()\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "\n",
        "#         train_loss.append([log_px, loss.item()])\n",
        "\n",
        "#         if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
        "#             print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
        "#                 batch_idx * len(x), len(train_loader.dataset),\n",
        "#                 PRINT_INTERVAL * batch_idx / len(train_loader),\n",
        "#                 np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
        "#                 1000 * (time.time() - start_time)\n",
        "#             ))\n",
        "\n",
        "\n",
        "# def test():\n",
        "#     start_time = time.time()\n",
        "#     val_loss = []\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for batch_idx, (x, _) in enumerate(test_loader):\n",
        "#             x = x.cuda()\n",
        "#             x_tilde, kl_d = model(x)\n",
        "#             loss_recons = F.mse_loss(x_tilde, x, size_average=False) / x.size(0)\n",
        "#             loss = loss_recons + kl_d\n",
        "#             val_loss.append(loss.item())\n",
        "\n",
        "#     print('\\nValidation Completed!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
        "#         np.asarray(val_loss).mean(0),\n",
        "#         time.time() - start_time\n",
        "#     ))\n",
        "#     return np.asarray(val_loss).mean(0)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axstZC9PH_DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def generate_reconstructions():\n",
        "#     model.eval()\n",
        "#     x, _ = test_loader.__iter__().next()\n",
        "#     x = x[:32].cuda()\n",
        "#     x_tilde, kl_div = model(x)\n",
        "\n",
        "#     x_cat = torch.cat([x, x_tilde], 0)\n",
        "#     images = (x_cat.cpu().data + 1) / 2\n",
        "\n",
        "#     save_image(\n",
        "#         images,\n",
        "#         'samples/vae_reconstructions_{}.png'.format(DATASET),\n",
        "#         nrow=8\n",
        "#     )\n",
        "\n",
        "\n",
        "# def generate_samples():\n",
        "#     model.eval()\n",
        "#     z_e_x = torch.randn(64, Z_DIM, 1, 1).cuda()\n",
        "#     x_tilde = model.decoder(z_e_x)\n",
        "\n",
        "#     images = (x_tilde.cpu().data + 1) / 2\n",
        "\n",
        "#     save_image(\n",
        "#         images,\n",
        "#         'samples/vae_samples_{}.png'.format(DATASET),\n",
        "#         nrow=8\n",
        "#     )\n",
        "\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFLvqQbbpaHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BEST_LOSS = 99999\n",
        "# LAST_SAVED = -1\n",
        "# for epoch in range(1, N_EPOCHS):\n",
        "#     print(\"Epoch {}:\".format(epoch))\n",
        "#     train()\n",
        "#     cur_loss = test()\n",
        "\n",
        "#     if cur_loss <= BEST_LOSS:\n",
        "#         BEST_LOSS = cur_loss\n",
        "#         LAST_SAVED = epoch\n",
        "#         print(\"Saving model!\")\n",
        "#         torch.save(model.state_dict(), 'models/{}_vae.pt'.format(DATASET))\n",
        "#     else:\n",
        "#         print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
        "\n",
        "#     generate_reconstructions()\n",
        "#     generate_samples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyBG8oz0hodo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(recon_x, x, mu, logvar) -> Variable:\n",
        "    # how well do input x and output recon_x agree?\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 16384))\n",
        "\n",
        "    # KLD is Kullback–Leibler divergence -- how much does one learned\n",
        "    # distribution deviate from another, in this specific case the\n",
        "    # learned distribution from the unit Gaussian\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # - D_{KL} = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    # note the negative D_{KL} in appendix B of the paper\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    # Normalise by same number of elements as in reconstruction\n",
        "    KLD /= BATCH_SIZE * 16384\n",
        "\n",
        "    # BCE tries to make our reconstruction as accurate as possible\n",
        "    # KLD tries to push the distributions as close as possible to unit Gaussian\n",
        "    return BCE + KLD\n",
        "\n",
        "# Dr Diederik Kingma: as if VAEs weren't enough, he also gave us Adam!\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdWJGPmBzGiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    # toggle model to train mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    # in the case of MNIST, len(train_loader.dataset) is 60000\n",
        "    # each `data` is of BATCH_SIZE samples and has shape [128, 1, 28, 28]\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = Variable(data)\n",
        "        if CUDA:\n",
        "            data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # push whole batch of data through VAE.forward() to get recon_loss\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        # calculate scalar loss\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        # calculate the gradient of the loss w.r.t. the graph leaves\n",
        "        # i.e. input variables -- by the power of pytorch!\n",
        "        loss.backward()\n",
        "        train_loss += loss.data#[0]\n",
        "        optimizer.step()\n",
        "        if batch_idx % LOG_INTERVAL == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.data/ len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_uoH4M1zHui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(epoch):\n",
        "    # toggle model to test / inference mode\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "\n",
        "    # each data is of BATCH_SIZE (default 128) samples\n",
        "    for i, (data, _) in enumerate(test_loader):\n",
        "        if CUDA:\n",
        "            # make sure this lives on the GPU\n",
        "            data = data.cuda()\n",
        "\n",
        "        # we're only going to infer, so no autograd at all required: volatile=True\n",
        "        data = Variable(data, volatile=True)\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        test_loss += loss_function(recon_batch, data, mu, logvar).data#[0]\n",
        "        if i == 0:\n",
        "          n = min(data.size(0), 8)\n",
        "          # for the first 128 batch of the epoch, show the first 8 input digits\n",
        "          # with right below them the reconstructed output digits\n",
        "          comparison = torch.cat([data[:n],\n",
        "                                  recon_batch.view(BATCH_SIZE, 3, 128, 128)[:n]])\n",
        "          save_image(comparison.data.cpu(),\n",
        "                     'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhAgS6ZOzTco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "9ad3d62a-68e6-4018-ffba-67bcdf72b716"
      },
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "\n",
        "    # 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\n",
        "    # digits in latent space\n",
        "    sample = Variable(torch.randn(64, ZDIMS))\n",
        "    if CUDA:\n",
        "        sample = sample.cuda()\n",
        "    sample = model.decode(sample).cpu()\n",
        "\n",
        "    # save out as an 8x8 matrix of MNIST digits\n",
        "    # this will give you a visual idea of how well latent space can generate things\n",
        "    # that look like digits\n",
        "    save_image(sample.data.view(64, 3, 128, 128),'results/sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-fe0952ef15a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-5b21b902d3cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# push whole batch of data through VAE.forward() to get recon_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# calculate scalar loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e3cf54fde712>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16384\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e3cf54fde712>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# h1 is [128, 400]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc21\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc22\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [1, 3, 3, 3], but got 2-dimensional input of size [384, 16384] instead"
          ]
        }
      ]
    }
  ]
}